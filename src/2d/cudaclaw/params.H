#ifndef __PARAMS_H__
#define __PARAMS_H__

#ifdef CUDA

#include "real.H"
#include "common.H"
#include "clawpack_mempool.H"
#include "clawpack_device.H"
#include "clawpack_CUDA_helper.H"

#include <assert.h>
#include <cuda_runtime.h>
#include <stdio.h>
#include <string>
#include <cstring>

// #define CHECK_BOUND


class pdeParam
{
    public:
        const int cellsX;			// number of cells on the horizontal, including ghost cells (unpadded)
        const int cellsY;			// number of cells on the vertical, including ghost cells
        const int numGhostCells;	// ghost cells for the boundaries
        const int numStates;	// number of states of the problem, number of scalars per cell
        const int numWaves;		// number of nonzero waves generated by the Riemann solver (usually as many as there are equations)
        const int numCoeff;		// number of different types medium properties

        bool second_order;		// second order accuracy computation flag

        real width;		       	// physical domain's width
        real height;       		// physical domain's height;
        real dx;		       	// physical domain's spacial discritization size on the horizontal
        real dy;		       	// physical domain's spacial discritization size on the vertical
        const real startX;		// physical domain's starting x in cartesian coordinates
        const real endX;		// physical domain's ending x in cartesian coordinates
        const real startY;		// physical domain's starting y in cartesian coordinates
        const real endY;		// physical domain's ending y in cartesian coordinates

        const real dt;			// time step to be used in the computation

        real* coefficients;		// physical medium coefficients

        // GPU residents
        real* q_tmp; // intermediate update holder
        real* qNew; // data, cells' states

        // Each entry in waveSpeedsX stores maximum u-velocity in one CUDA block. So the size
        // of waveSpeedsX should be number of CUDA blocks for this AMR grid patch
        // The same rule applies to waveSpeedsY
        // after calling reduceMax_simplified, waveSpeedsX[0] has the maximum u velocity on this grid, and
        // waveSpeedsY[0] has the maximum v velocity on this grid.
        volatile real* waveSpeedsX;		// speed of horizontal waves
        volatile real* waveSpeedsY;		// speed of vertical waves

        real* cfl_grid; // an array of size 1xSPACEDIM, storing cfl number in current grid patch in all directions

        const int mcapa; // index in aux array that corresponds to capacity variable. 0-indexed.
        const int dev_id; // ID of the device on which storage are allocated
        const int id; // local id of this grid

        class TagAndDev 
        {
            public:
                int tag;
                int dev_id;
        };

        pdeParam(int cellsX, int cellsY, int numGhostCells, int numStates, int numWaves, int numCoeff,
                real startX, real endX, real startY, real endY,
                real dt_,
                real* q_tmp_, real* qNew_, 
                real* coefficients_,
                real* waveSpeedsX_, real* waveSpeedsY_,
                real* cfl_grid_, const int mcapa_, const int id_, int dev_id_):
                cellsX(cellsX), cellsY(cellsY), numGhostCells(numGhostCells), numStates(numStates), numWaves(numWaves), numCoeff(numCoeff),
                startX(startX), endX(endX), startY(startY), endY(endY), dt(dt_),
                q_tmp(q_tmp_), qNew(qNew_), waveSpeedsX(waveSpeedsX_), waveSpeedsY(waveSpeedsY_),
                coefficients(coefficients_), cfl_grid(cfl_grid_), mcapa(mcapa_),
                id(id_), dev_id(dev_id_)
        {

            assert( (cellsX-2*numGhostCells) > 0 );
            assert( (cellsY-2*numGhostCells) > 0 );

            width = endX-startX;
            height = endY-startY;
            dx = width/cellsX;
            dy = height/cellsY;

            second_order = true;

        }

        // copy constructor
        pdeParam (const pdeParam&) = default;

        // assignment constructor
        pdeParam& operator=(const pdeParam& other) = delete;

        ~pdeParam() {}

        void static CUDART_CB cudaCallback_release_gpu(cudaStream_t event, cudaError_t status, void *data) {
            checkCudaErrors(status);
            TagAndDev* td = static_cast<TagAndDev*>(data);
            clawpack_mempool_release_gpu(td->tag, td->dev_id);
            delete td;
        }


        void setOrderOfAccuracy(int order)
        {
            if(order == 2)
                second_order = true;
            else
                second_order = false;
        }


        // GETTER AND SETTER FUNCTIONS

        // Dictates how the memory layout for q_tmp will be
        __device__ __host__ 
        inline int getIndex_q_tmp(int row, int column, int state)
        {
            // column => cellsX, row => cellsY
            //
            // SOA
            // state is the slowest moving dimension now, then row, then column
            return (state*cellsX*cellsY + row*cellsX + column);
            //
            // AOS
            // return (state + column*numStates + row*numStates*cellsX);
        }
        inline __device__ real &getElement_q_tmp(int row, int column, int state)
        {
#ifdef CHECK_BOUND
            size_t idx = getIndex_q_tmp(row, column, state);
            size_t bound = cellsX*cellsY*numStates;
            if ( idx >= bound) {
                printf("Index %d out of bound %d in getElement_q_tmp.\n", idx, bound);
                assert(0);
            }
#endif
            return q_tmp[getIndex_q_tmp(row, column, state)];
        }
        inline __device__ void setElement_q_tmp(int row, int column, int state, real setValue)
        {
#ifdef CHECK_BOUND
            size_t idx = getIndex_q_tmp(row, column, state);
            size_t bound = cellsX*cellsY*numStates;
            if ( idx >= bound) {
                printf("Index %d out of bound %d in setElement_q_tmp.\n", idx, bound);
                assert(0);
            }
#endif
            q_tmp[getIndex_q_tmp(row, column, state)] = setValue;
        }

        // QNEW
        // Dictates how the memory layout for qNew will be
        inline __device__ int getIndex_qNew(int row, int column, int state)
        {
            // column => cellsX, row => cellsY
            //
            // SOA
            // state is the slowest moving dimension now, then row, then column
            // return (state*cellsX*cellsY + row*cellsX + column);
            //
            // AOS
            return (state + column*numStates + row*numStates*cellsX);
        }
        inline __device__ real &getElement_qNew(int row, int column, int state)
        {
#ifdef CHECK_BOUND
            size_t idx = getIndex_qNew(row, column, state);
            size_t bound = cellsX*cellsY*numStates;
            if ( idx >= bound) {
                printf("Index %d out of bound %d in getElement_qNew.\n", idx, bound);
                assert(0);
            }
#endif
            return qNew[getIndex_qNew(row, column, state)];
        }
        inline __device__ void setElement_qNew(int row, int column, int state, real setValue)
        {
#ifdef CHECK_BOUND
            size_t idx = getIndex_qNew(row, column, state);
            size_t bound = cellsX*cellsY*numStates;
            if ( idx >= bound) {
                printf("Index %d out of bound %d in setElement_qNew.\n", idx, bound);
                assert(0);
            }
#endif
            qNew[getIndex_qNew(row, column, state)] = setValue;
        }


        // COEFFICIENTS
        inline __device__ __host__ int getIndex_coeff(int row, int column, int coeff)
        {
            // column => cellsX, row => cellsY
            //
            // SOA
            // Usual C/C++ row major order
            // coeff is the slowest moving dimension now, then row, then column
            // return (coeff*cellsX*cellsY + row*cellsX + column);
            //
            // AOS
            return (coeff + column*numCoeff + row*numCoeff*cellsX);
        }

        inline __device__ real &getElement_coeff(int row, int column, int coeff)
        {
#ifdef CHECK_BOUND
            size_t idx = getIndex_coeff(row, column, coeff);
            size_t bound = cellsX*cellsY*numCoeff;
            if ( idx >= bound) {
                printf("Index %d out of bound %d in getElement_coeff.\n", idx, bound);
                assert(0);
            }
#endif
            return coefficients[getIndex_coeff(row, column, coeff)];
        }

        inline __device__ void setElement_coeff(int row, int column, int coeff, real setValue)
        {
#ifdef CHECK_BOUND
            size_t idx = getIndex_coeff(row, column, coeff);
            size_t bound = cellsX*cellsY*numCoeff;
            if ( idx >= bound) {
                printf("Index %d out of bound %d in setElement_coeff.\n", idx, bound);
                assert(0);
            }
#endif
            coefficients[getIndex_coeff(row, column, coeff)] = setValue;
        }

        inline void alloc_waveSpeedsX(size_t nWords) {
            size_t sz = nWords*sizeof(real);
            waveSpeedsX = (real*) clawpack_mempool_alloc_gpu_hold(sz, this->dev_id, this->id);
        }

        inline void alloc_waveSpeedsY(size_t nWords) {
            size_t sz = nWords*sizeof(real);
            waveSpeedsY = (real*) clawpack_mempool_alloc_gpu_hold(sz, this->dev_id, this->id);
        }

        // add cuda callback function to free memory allocated and managed by this pdeParam object
        // The memory will be free after:
        // all CUDA events in the stream earlier than this function call are finished
        inline void register_allocated_memory() {
            cudaStream_t stream;
            get_cuda_stream(this->id, this->dev_id, &stream);

            TagAndDev* td = new TagAndDev();
            td->tag = this->id;
            td->dev_id = this->dev_id;
            cudaStreamAddCallback(stream, pdeParam::cudaCallback_release_gpu, (void*) td, 0);
        }

};

#endif

#endif
